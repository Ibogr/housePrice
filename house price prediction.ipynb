Done in this project,

Data download
Exploratory data analysis(EDA)
Detecting and Filling in missing data
Visualization
Correlation
Cleaning outliers
Feature engineering
Machine learning
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.simplefilter(action="ignore")
# read data from '.csv'
data_ = pd.read_csv('train.csv')
data_
Id	MSSubClass	MSZoning	LotFrontage	LotArea	Street	Alley	LotShape	LandContour	Utilities	...	PoolArea	PoolQC	Fence	MiscFeature	MiscVal	MoSold	YrSold	SaleType	SaleCondition	SalePrice
0	1	60	RL	65.0	8450	Pave	NaN	Reg	Lvl	AllPub	...	0	NaN	NaN	NaN	0	2	2008	WD	Normal	208500
1	2	20	RL	80.0	9600	Pave	NaN	Reg	Lvl	AllPub	...	0	NaN	NaN	NaN	0	5	2007	WD	Normal	181500
2	3	60	RL	68.0	11250	Pave	NaN	IR1	Lvl	AllPub	...	0	NaN	NaN	NaN	0	9	2008	WD	Normal	223500
3	4	70	RL	60.0	9550	Pave	NaN	IR1	Lvl	AllPub	...	0	NaN	NaN	NaN	0	2	2006	WD	Abnorml	140000
4	5	60	RL	84.0	14260	Pave	NaN	IR1	Lvl	AllPub	...	0	NaN	NaN	NaN	0	12	2008	WD	Normal	250000
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
1455	1456	60	RL	62.0	7917	Pave	NaN	Reg	Lvl	AllPub	...	0	NaN	NaN	NaN	0	8	2007	WD	Normal	175000
1456	1457	20	RL	85.0	13175	Pave	NaN	Reg	Lvl	AllPub	...	0	NaN	MnPrv	NaN	0	2	2010	WD	Normal	210000
1457	1458	70	RL	66.0	9042	Pave	NaN	Reg	Lvl	AllPub	...	0	NaN	GdPrv	Shed	2500	5	2010	WD	Normal	266500
1458	1459	20	RL	68.0	9717	Pave	NaN	Reg	Lvl	AllPub	...	0	NaN	NaN	NaN	0	4	2010	WD	Normal	142125
1459	1460	20	RL	75.0	9937	Pave	NaN	Reg	Lvl	AllPub	...	0	NaN	NaN	NaN	0	6	2008	WD	Normal	147500
1460 rows × 81 columns

data_.shape
(1460, 81)
# let's copy data
df = data_.copy()
df.columns
Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',
       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',
       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',
       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',
       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',
       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',
       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',
       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',
       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',
       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',
       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',
       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',
       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',
       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',
       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',
       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',
       'SaleCondition', 'SalePrice'],
      dtype='object')
# let's find null values
df.isnull().sum().head(20)
Id                 0
MSSubClass         0
MSZoning           0
LotFrontage      259
LotArea            0
Street             0
Alley           1369
LotShape           0
LandContour        0
Utilities          0
LotConfig          0
LandSlope          0
Neighborhood       0
Condition1         0
Condition2         0
BldgType           0
HouseStyle         0
OverallQual        0
OverallCond        0
YearBuilt          0
dtype: int64
#Catching Numerical and Categorical Dtypes. based on 'df'
obj=[]
int64=[]
float64=[]
for i in df.columns:
    if df[i].dtype=='O':
        obj.append(i)
    elif df[i].dtype=="float64":
        float64.append(i)
    else:
        int64.append(i)
print("<**type object**>:    ",obj)
print("-*-"*36)
print("<**type int**>:    ",int64)
print("-*-"*36)
print("<**type float**>:    ",float64)
<**type object**>:     ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
<**type int**>:     ['Id', 'MSSubClass', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SalePrice']
-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-
<**type float**>:     ['LotFrontage', 'MasVnrArea', 'GarageYrBlt']
unique_values = []
for col in obj:
    unique_values.append(df[col].unique().size)
plt.figure(figsize=(10,6))
plt.title('No. Unique values of Categorical Features')
plt.xticks(rotation=80)
sns.barplot(x=obj,y=unique_values);

df.MSZoning = df.MSZoning.replace({'RL':'Residential Low Density',
                  'A':'Agriculture',
                  'C(all)':'Commercial',
                  'FV':'Floating Village Residential',
                  'I':'Industrial',
                  'RH':'Residential High Density',
                  'RP':'Residential Low Density Park ',
                  'RM':'Residential Medium Density'})
df.MSZoning.value_counts()
Residential Low Density         1151
Residential Medium Density       218
Floating Village Residential      65
Residential High Density          16
C (all)                           10
Name: MSZoning, dtype: int64
plt.figure(figsize=(10,5))
sns.countplot(df['MSZoning'])
plt.xticks(rotation=80)
;
''

specific_data = df[df['MSZoning']=='Residential Low Density']
specific_data
Id	MSSubClass	MSZoning	LotFrontage	LotArea	Street	Alley	LotShape	LandContour	Utilities	...	PoolArea	PoolQC	Fence	MiscFeature	MiscVal	MoSold	YrSold	SaleType	SaleCondition	SalePrice
0	1	60	Residential Low Density	65.0	8450	Pave	NaN	Reg	Lvl	AllPub	...	0	NaN	NaN	NaN	0	2	2008	WD	Normal	208500
1	2	20	Residential Low Density	80.0	9600	Pave	NaN	Reg	Lvl	AllPub	...	0	NaN	NaN	NaN	0	5	2007	WD	Normal	181500
2	3	60	Residential Low Density	68.0	11250	Pave	NaN	IR1	Lvl	AllPub	...	0	NaN	NaN	NaN	0	9	2008	WD	Normal	223500
3	4	70	Residential Low Density	60.0	9550	Pave	NaN	IR1	Lvl	AllPub	...	0	NaN	NaN	NaN	0	2	2006	WD	Abnorml	140000
4	5	60	Residential Low Density	84.0	14260	Pave	NaN	IR1	Lvl	AllPub	...	0	NaN	NaN	NaN	0	12	2008	WD	Normal	250000
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
1455	1456	60	Residential Low Density	62.0	7917	Pave	NaN	Reg	Lvl	AllPub	...	0	NaN	NaN	NaN	0	8	2007	WD	Normal	175000
1456	1457	20	Residential Low Density	85.0	13175	Pave	NaN	Reg	Lvl	AllPub	...	0	NaN	MnPrv	NaN	0	2	2010	WD	Normal	210000
1457	1458	70	Residential Low Density	66.0	9042	Pave	NaN	Reg	Lvl	AllPub	...	0	NaN	GdPrv	Shed	2500	5	2010	WD	Normal	266500
1458	1459	20	Residential Low Density	68.0	9717	Pave	NaN	Reg	Lvl	AllPub	...	0	NaN	NaN	NaN	0	4	2010	WD	Normal	142125
1459	1460	20	Residential Low Density	75.0	9937	Pave	NaN	Reg	Lvl	AllPub	...	0	NaN	NaN	NaN	0	6	2008	WD	Normal	147500
1151 rows × 81 columns

df.groupby(df['MSZoning']=='Residential Low Density').agg({'SalePrice':['count','min','max','std','mean']}).round()
SalePrice
count	min	max	std	mean
MSZoning					
False	309	34900	475000	61191.0	143360.0
True	1151	39300	755000	80766.0	191005.0
# let's split up columns that include null values.
nullvalues = []
for null in df:
    if df[null].isnull().sum()>200:
        nullvalues.append(null)
    else:
        pass
nullvalues
['LotFrontage', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']
#let's drop null values over 200
df.drop(['LotFrontage', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'],axis=1,inplace=True)
#let's fill in null values several method
df['BsmtQual'].fillna((df['BsmtQual'].ffill),inplace=True)
df["MasVnrArea"].fillna((df['MasVnrArea'].mean()),inplace=True)
df['BsmtCond'].fillna(df['BsmtCond'].ffill(),inplace=True)
df['GarageFinish'].fillna(df['GarageFinish'].ffill(),inplace=True)
df.dropna(inplace=True)
df.describe(percentiles=[0.01,0.99,0.25,0.75,0.5]).drop('count').round(2).T
mean	std	min	1%	25%	50%	75%	99%	max
Id	731.23	421.78	1.0	14.37	366.25	730.5	1098.75	1443.63	1460.0
MSSubClass	56.14	41.25	20.0	20.00	20.00	50.0	70.00	190.00	190.0
LotArea	10706.29	10336.62	1300.0	1876.77	7744.00	9600.0	11760.75	39727.70	215245.0
OverallQual	6.22	1.32	2.0	4.00	5.00	6.0	7.00	10.00	10.0
OverallCond	5.60	1.08	2.0	3.00	5.00	5.0	6.00	9.00	9.0
YearBuilt	1973.03	29.56	1880.0	1900.00	1956.00	1976.0	2001.00	2009.00	2010.0
YearRemodAdd	1985.67	20.30	1950.0	1950.00	1968.00	1994.5	2004.00	2009.00	2010.0
MasVnrArea	110.36	185.60	0.0	0.00	0.00	0.0	174.00	808.60	1600.0
BsmtFinSF1	464.23	458.79	0.0	0.00	0.00	413.0	733.00	1593.79	5644.0
BsmtFinSF2	49.22	166.20	0.0	0.00	0.00	0.0	0.00	858.64	1474.0
BsmtUnfSF	582.49	439.95	0.0	0.00	248.00	489.0	815.75	1798.15	2336.0
TotalBsmtSF	1095.95	405.55	105.0	419.84	819.75	1021.5	1324.00	2156.15	6110.0
1stFlrSF	1176.22	386.64	438.0	525.37	894.00	1098.0	1414.00	2220.78	4692.0
2ndFlrSF	357.14	440.32	0.0	0.00	0.00	0.0	740.50	1405.86	2065.0
LowQualFinSF	4.22	40.71	0.0	0.00	0.00	0.0	0.00	135.12	572.0
GrLivArea	1537.59	520.58	438.0	756.44	1160.00	1480.0	1791.50	3129.64	5642.0
BsmtFullBath	0.44	0.52	0.0	0.00	0.00	0.0	1.00	1.00	2.0
BsmtHalfBath	0.06	0.24	0.0	0.00	0.00	0.0	0.00	1.00	2.0
FullBath	1.58	0.55	0.0	1.00	1.00	2.0	2.00	3.00	3.0
HalfBath	0.40	0.50	0.0	0.00	0.00	0.0	1.00	1.00	2.0
BedroomAbvGr	2.86	0.78	0.0	1.00	2.00	3.0	3.00	5.00	6.0
KitchenAbvGr	1.03	0.17	1.0	1.00	1.00	1.0	1.00	2.00	3.0
TotRmsAbvGrd	6.55	1.59	3.0	4.00	5.00	6.0	7.00	11.00	12.0
Fireplaces	0.65	0.65	0.0	0.00	0.00	1.0	1.00	2.00	3.0
GarageYrBlt	1978.60	24.77	1900.0	1916.00	1962.00	1980.0	2002.00	2009.00	2010.0
GarageCars	1.87	0.63	1.0	1.00	1.00	2.0	2.00	3.00	4.0
GarageArea	501.45	186.76	160.0	190.11	377.50	484.0	583.00	1017.78	1418.0
WoodDeckSF	99.38	127.54	0.0	0.00	0.00	6.0	174.50	510.26	857.0
OpenPorchSF	47.78	65.36	0.0	0.00	0.00	28.0	70.00	283.89	547.0
EnclosedPorch	21.26	60.84	0.0	0.00	0.00	0.0	0.00	262.15	552.0
3SsnPorch	3.59	30.22	0.0	0.00	0.00	0.0	0.00	168.00	508.0
ScreenPorch	16.43	58.05	0.0	0.00	0.00	0.0	0.00	272.26	480.0
PoolArea	3.01	41.96	0.0	0.00	0.00	0.0	0.00	0.00	738.0
MiscVal	42.93	508.06	0.0	0.00	0.00	0.0	0.00	700.00	15500.0
MoSold	6.33	2.70	1.0	1.00	5.00	6.0	8.00	12.00	12.0
YrSold	2007.81	1.33	2006.0	2006.00	2007.00	2008.0	2009.00	2010.00	2010.0
SalePrice	186761.78	78913.85	35311.0	75370.00	135000.00	168500.0	220000.00	443944.43	755000.0
modelColumns={'YrSold','MoSold','OpenPorchSF','GarageCars','LotArea','YearRemodAdd','OverallQual','GrLivArea','FullBath','YearBuilt','1stFlrSF','SalePrice'}
modelColumns
{'1stFlrSF',
 'FullBath',
 'GarageCars',
 'GrLivArea',
 'LotArea',
 'MoSold',
 'OpenPorchSF',
 'OverallQual',
 'SalePrice',
 'YearBuilt',
 'YearRemodAdd',
 'YrSold'}
data = pd.DataFrame(data=df,columns=modelColumns)
data
OverallQual	YearBuilt	SalePrice	GarageCars	OpenPorchSF	LotArea	GrLivArea	1stFlrSF	YearRemodAdd	YrSold	FullBath	MoSold
0	7	2003	208500	2	61	8450	1710	856	2003	2008	2	2
1	6	1976	181500	2	0	9600	1262	1262	1976	2007	2	5
2	7	2001	223500	2	42	11250	1786	920	2002	2008	2	9
3	7	1915	140000	3	35	9550	1717	961	1970	2006	1	2
4	8	2000	250000	3	84	14260	2198	1145	2000	2008	2	12
...	...	...	...	...	...	...	...	...	...	...	...	...
1455	6	1999	175000	2	40	7917	1647	953	2000	2007	2	8
1456	6	1978	210000	2	0	13175	2073	2073	1988	2010	2	2
1457	7	1941	266500	1	60	9042	2340	1188	2006	2010	2	5
1458	5	1950	142125	1	0	9717	1078	1078	1996	2010	1	4
1459	5	1965	147500	1	68	9937	1256	1256	1965	2008	1	6
1338 rows × 12 columns

data = data.rename(columns={'MoSold':'MonthlyS',
            'OpenPorchSF':'PorchSq',
            'OverallQual':'RateOfHouse',
            'LotArea':'LandSquare',
            'YearRemodAdd':'RemodelDate',
            'GrLivArea':'BuildingSq',
            'FullBath':'Bathroom',
            '1stFlrSF':'1FloorSquare'
})
data['Seasons'] = ['winter' if i in [12, 1, 2] else
                   'spring' if i in [3, 4, 5] else
                   'summer' if i in [6, 7, 8] else
                   'autumn' if i in [9, 10, 11] else ''
                   for i in data['MonthlyS']]
data['Garden']=data['LandSquare']-data['BuildingSq']
data.shape
(1338, 14)
data.columns
Index(['RateOfHouse', 'YearBuilt', 'SalePrice', 'GarageCars', 'PorchSq',
       'LandSquare', 'BuildingSq', '1FloorSquare', 'RemodelDate', 'YrSold',
       'Bathroom', 'MonthlyS', 'Seasons', 'Garden'],
      dtype='object')
data.info()
<class 'pandas.core.frame.DataFrame'>
Int64Index: 1338 entries, 0 to 1459
Data columns (total 14 columns):
 #   Column        Non-Null Count  Dtype 
---  ------        --------------  ----- 
 0   RateOfHouse   1338 non-null   int64 
 1   YearBuilt     1338 non-null   int64 
 2   SalePrice     1338 non-null   int64 
 3   GarageCars    1338 non-null   int64 
 4   PorchSq       1338 non-null   int64 
 5   LandSquare    1338 non-null   int64 
 6   BuildingSq    1338 non-null   int64 
 7   1FloorSquare  1338 non-null   int64 
 8   RemodelDate   1338 non-null   int64 
 9   YrSold        1338 non-null   int64 
 10  Bathroom      1338 non-null   int64 
 11  MonthlyS      1338 non-null   int64 
 12  Seasons       1338 non-null   object
 13  Garden        1338 non-null   int64 
dtypes: int64(13), object(1)
memory usage: 156.8+ KB
# let's check lowest and biggest prices
min_price = data['SalePrice'].min()
max_price = data['SalePrice'].max()
print(f'min Price: $ {min_price}')
print(f'max Price: $ {max_price}')
min Price: $ 35311
max Price: $ 755000
# let's catch outliers of data
data.describe(percentiles=[0.01,0.99,0.25,0.75,0.5]).drop('count').round(2).T
mean	std	min	1%	25%	50%	75%	99%	max
RateOfHouse	6.22	1.32	2.0	4.00	5.00	6.0	7.00	10.00	10.0
YearBuilt	1973.03	29.56	1880.0	1900.00	1956.00	1976.0	2001.00	2009.00	2010.0
SalePrice	186761.78	78913.85	35311.0	75370.00	135000.00	168500.0	220000.00	443944.43	755000.0
GarageCars	1.87	0.63	1.0	1.00	1.00	2.0	2.00	3.00	4.0
PorchSq	47.78	65.36	0.0	0.00	0.00	28.0	70.00	283.89	547.0
LandSquare	10706.29	10336.62	1300.0	1876.77	7744.00	9600.0	11760.75	39727.70	215245.0
BuildingSq	1537.59	520.58	438.0	756.44	1160.00	1480.0	1791.50	3129.64	5642.0
1FloorSquare	1176.22	386.64	438.0	525.37	894.00	1098.0	1414.00	2220.78	4692.0
RemodelDate	1985.67	20.30	1950.0	1950.00	1968.00	1994.5	2004.00	2009.00	2010.0
YrSold	2007.81	1.33	2006.0	2006.00	2007.00	2008.0	2009.00	2010.00	2010.0
Bathroom	1.58	0.55	0.0	1.00	1.00	2.0	2.00	3.00	3.0
MonthlyS	6.33	2.70	1.0	1.00	5.00	6.0	8.00	12.00	12.0
Garden	9168.71	10216.05	71.0	681.03	6372.25	8056.5	9982.75	36881.49	213209.0
# Exploratory Data Analysis
plt.figure(figsize=(30,10))
sns.heatmap(data.corr(), vmax=1, vmin=-1, annot=True, cmap="GnBu")
plt.title('Heatmap',size=40)
plt.show()

sns.distplot(data['SalePrice'], color='b',hist=False,vertical=False,rug=True)
plt.title("Sale Price DistributionPlot")
plt.xlabel('Sale Price')
plt.ylabel('Frequency')
plt.show()
# tabloda gorulmdugu gibi target kolonumuz sag a carpiktir.
#   - Mean>Median>Mod
#   - Ortalama, aşırı puanların bulunduğu sağ tarafa doğru çekilmekte ve böylece ortanca ortalamanın solunda kalmaktadır.
#   - Değerlerin çoğu ortalamanın altında

plt.scatter(x=data['BuildingSq'], y=data['SalePrice'], color="orange", edgecolors="#000000", linewidths=0.5);
plt.xlabel("BuildingSq"); plt.ylabel("SalePrice");

# let's define outliers
Q1 = data['BuildingSq'].quantile(0.25)
Q3 = data['BuildingSq'].quantile(0.75)

IQR = Q3 - Q1
lower_bound = Q1- 1.5*IQR
upper_bound = Q3 + 1.5*IQR


print("lower bound is " + str(lower_bound))
print('-'*40)
print("upper bound is " + str(upper_bound))
print('-'*40)
print (Q1)
print('-'*40)
print (Q3)
print('-'*40)
lower bound is 212.75
----------------------------------------
upper bound is 2738.75
----------------------------------------
1160.0
----------------------------------------
1791.5
----------------------------------------
outliers_vector = (data['BuildingSq'] < (lower_bound)) | (data['BuildingSq'] >(upper_bound))
outliers = data['BuildingSq'][outliers_vector]
# let's check outliers index,
outliers.index.value_counts
<bound method IndexOpsMixin.value_counts of Int64Index([  58,  118,  185,  197,  231,  304,  324,  496,  523,  583,  608,
             691,  769,  798,  803,  961, 1024, 1031, 1046, 1142, 1169, 1175,
            1182, 1268, 1298, 1312, 1328, 1353, 1386],
           dtype='int64')>
data[outliers_vector]=data['BuildingSq'].mean()
# let's define outliers
Q1 = data['LandSquare'].quantile(0.25)
Q3 = data['LandSquare'].quantile(0.75)

IQR = Q3 - Q1
lower_bound = Q1- 1.5*IQR
upper_bound = Q3 + 1.5*IQR


print("lower bound is " + str(lower_bound))
print('-'*40)
print("upper bound is " + str(upper_bound))
print('-'*40)
print (Q1)
print('-'*40)
print (Q3)
print('-'*40)
lower bound is 1500.0
----------------------------------------
upper bound is 17500.0
----------------------------------------
7500.0
----------------------------------------
11500.0
----------------------------------------
outliers_vector = (data['LandSquare'] < (lower_bound)) | (data['LandSquare'] >(upper_bound))
outliers = data['LandSquare'][outliers_vector]
data[outliers_vector]=data['LandSquare'].mean()
data = data.drop(data[data['YrSold'] == (10320.181592565039)].index)
data = data.drop(data[data['YrSold'] == (1537.58520179)].index)
data.groupby([data['YrSold'].round(),'Seasons']).agg({'SalePrice':['count','min','max','std','mean']}).round()
SalePrice
count	min	max	std	mean
YrSold	Seasons					
1538.0	1537.585201793722	29	1538.0	1538.0	0.0	1538.0
2006.0	autumn	47	35311.0	360000.0	73740.0	187122.0
spring	79	79000.0	369900.0	55273.0	169223.0
summer	117	79900.0	374000.0	60751.0	177625.0
winter	26	98600.0	290000.0	52662.0	185032.0
2007.0	autumn	44	67000.0	392000.0	75994.0	202398.0
spring	76	87000.0	466500.0	71918.0	166687.0
summer	131	64500.0	440000.0	66258.0	184375.0
winter	34	75000.0	340000.0	73488.0	190996.0
2008.0	autumn	47	100000.0	446261.0	76886.0	186643.0
spring	67	68500.0	412500.0	64129.0	174665.0
summer	111	40000.0	426000.0	65931.0	182844.0
winter	30	108959.0	372402.0	64492.0	184539.0
2009.0	autumn	63	76000.0	402861.0	76392.0	179128.0
spring	71	82500.0	555000.0	74676.0	179895.0
summer	126	60000.0	501837.0	74317.0	186009.0
winter	30	60000.0	320000.0	69127.0	172487.0
2010.0	spring	92	68400.0	611657.0	82059.0	183622.0
summer	34	55993.0	394432.0	60886.0	165077.0
winter	22	102776.0	319900.0	55725.0	178088.0
data.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T
0.00	0.05	0.50	0.95	0.99	1.00
RateOfHouse	2.000000	4.000000	6.0	9.00	1537.585202	1537.585202
YearBuilt	1537.585202	1913.750000	1975.0	2007.00	2009.000000	2010.000000
SalePrice	1537.585202	87750.000000	163500.0	318000.00	394712.750000	611657.000000
GarageCars	1.000000	1.000000	2.0	3.00	1537.585202	1537.585202
PorchSq	0.000000	0.000000	28.5	204.25	1537.585202	1537.585202
LandSquare	1526.000000	2522.000000	9247.5	14444.00	16578.750000	17500.000000
BuildingSq	438.000000	864.000000	1471.5	2295.25	2630.750000	2730.000000
1FloorSquare	438.000000	684.000000	1094.0	1766.00	2114.000000	2633.000000
RemodelDate	1537.585202	1950.000000	1994.0	2007.00	2009.000000	2010.000000
YrSold	1537.585202	2006.000000	2008.0	2010.00	2010.000000	2010.000000
Bathroom	0.000000	1.000000	2.0	2.00	1537.585202	1537.585202
MonthlyS	1.000000	2.000000	6.0	12.00	1537.585202	1537.585202
Garden	378.000000	1537.585202	7831.5	12667.25	14794.250000	16274.000000
dff= pd.get_dummies(data,drop_first=True)
dff
RateOfHouse	YearBuilt	SalePrice	GarageCars	PorchSq	LandSquare	BuildingSq	1FloorSquare	RemodelDate	YrSold	Bathroom	MonthlyS	Garden	Seasons_autumn	Seasons_spring	Seasons_summer	Seasons_winter
0	7.0	2003.0	208500.0	2.0	61.0	8450.0	1710.0	856.0	2003.0	2008.0	2.0	2.0	6740.0	0	0	0	1
1	6.0	1976.0	181500.0	2.0	0.0	9600.0	1262.0	1262.0	1976.0	2007.0	2.0	5.0	8338.0	0	1	0	0
2	7.0	2001.0	223500.0	2.0	42.0	11250.0	1786.0	920.0	2002.0	2008.0	2.0	9.0	9464.0	1	0	0	0
3	7.0	1915.0	140000.0	3.0	35.0	9550.0	1717.0	961.0	1970.0	2006.0	1.0	2.0	7833.0	0	0	0	1
4	8.0	2000.0	250000.0	3.0	84.0	14260.0	2198.0	1145.0	2000.0	2008.0	2.0	12.0	12062.0	0	0	0	1
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
1455	6.0	1999.0	175000.0	2.0	40.0	7917.0	1647.0	953.0	2000.0	2007.0	2.0	8.0	6270.0	0	0	1	0
1456	6.0	1978.0	210000.0	2.0	0.0	13175.0	2073.0	2073.0	1988.0	2010.0	2.0	2.0	11102.0	0	0	0	1
1457	7.0	1941.0	266500.0	1.0	60.0	9042.0	2340.0	1188.0	2006.0	2010.0	2.0	5.0	6702.0	0	1	0	0
1458	5.0	1950.0	142125.0	1.0	0.0	9717.0	1078.0	1078.0	1996.0	2010.0	1.0	4.0	8639.0	0	1	0	0
1459	5.0	1965.0	147500.0	1.0	68.0	9937.0	1256.0	1256.0	1965.0	2008.0	1.0	6.0	8681.0	0	0	1	0
1276 rows × 17 columns

from sklearn import model_selection
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score
from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score
from sklearn.metrics import mean_squared_error
from sklearn.cluster import KMeans
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import GradientBoostingRegressor

# !conda install lightgbm
# from lightgbm import LGBMClassifier
 Run Base Model
df = pd.get_dummies(df,drop_first=True)
df
Id	MSSubClass	LotArea	OverallQual	OverallCond	YearBuilt	YearRemodAdd	MasVnrArea	BsmtFinSF1	BsmtFinSF2	...	SaleType_ConLI	SaleType_ConLw	SaleType_New	SaleType_Oth	SaleType_WD	SaleCondition_AdjLand	SaleCondition_Alloca	SaleCondition_Family	SaleCondition_Normal	SaleCondition_Partial
0	1	60	8450	7	5	2003	2003	196.0	706	0	...	0	0	0	0	1	0	0	0	1	0
1	2	20	9600	6	8	1976	1976	0.0	978	0	...	0	0	0	0	1	0	0	0	1	0
2	3	60	11250	7	5	2001	2002	162.0	486	0	...	0	0	0	0	1	0	0	0	1	0
3	4	70	9550	7	5	1915	1970	0.0	216	0	...	0	0	0	0	1	0	0	0	0	0
4	5	60	14260	8	5	2000	2000	350.0	655	0	...	0	0	0	0	1	0	0	0	1	0
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
1455	1456	60	7917	6	5	1999	2000	0.0	0	0	...	0	0	0	0	1	0	0	0	1	0
1456	1457	20	13175	6	6	1978	1988	119.0	790	163	...	0	0	0	0	1	0	0	0	1	0
1457	1458	70	9042	7	9	1941	2006	0.0	275	0	...	0	0	0	0	1	0	0	0	1	0
1458	1459	20	9717	5	6	1950	1996	0.0	49	1029	...	0	0	0	0	1	0	0	0	1	0
1459	1460	20	9937	5	6	1965	1965	0.0	830	290	...	0	0	0	0	1	0	0	0	1	0
1338 rows × 228 columns

# let's run base model for linear regration
X = df.drop(['SalePrice'],axis=1)
y = df['SalePrice']
# Shuffle and split the data into training and testing subsets for base model

X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.30,random_state=100)
model = LinearRegression()
model.fit(X_train,y_train)
y_predict = model.predict(X_test)
# y_predict
train_score = model.score(X_train,y_train)
test_score = model.score(X_test,y_test)
# score = r2_score(y_test, y_predict)
print('train results:',train_score)
print('test result:',test_score)
# print('test R²',score)
# print("MSPE",mean_absolute_percentage_error(y_test,y_predict))
train results: 0.9315690701600345
test result: 0.6581110330603388
housing_predictions = model.predict(X_test)
error = mean_squared_error(y_test,housing_predictions)
rmse = np.sqrt(error)
rmse
46232.264845949845
y_test.mean()
191283.16169154228
rmse/y_test.mean()
0.24169542387898557
sns.scatterplot(x=y_test, y=housing_predictions);

 
X = dff.drop(['SalePrice'],axis=1)
y = dff['SalePrice']
# Shuffle and split the data into training and testing subsets

X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.30,random_state=100)
#let's do XGBoosting
xgb = XGBRegressor()
xgb.fit(X_train,y_train)
pred = xgb.predict(X_test)
print('XGBReg_score:', xgb.score(X_test,y_test))
housing_predictionsxgb = xgb.predict(X_test)
error = mean_squared_error(y_test,housing_predictionsxgb)
rmse3 = np.sqrt(error)
print('rmse_score: ',rmse3/y_test.mean())
XGBReg_score: 0.8547312167350716
rmse_score:  0.16436233952961427
sns.scatterplot(x=y_test, y=pred, hue=y_test);

Model Linear Regration
model1 = LinearRegression()
model1.fit(X_train,y_train)
y_predic = model1.predict(X_test)
train_score = model1.score(X_train,y_train)
test_score = model1.score(X_test,y_test)
# score = r2_score(y_test, y_predic)
print('train results:',train_score)
print('test result:',test_score)
# print("MSPE",mean_absolute_percentage_error(y_test,y_predic))
train results: 0.8479783966082296
test result: 0.8560645277085733
housing_predictionsLR = model1.predict(X_test)
error = mean_squared_error(y_test,housing_predictionsLR)
rmse1 = np.sqrt(error)
rmse1/y_test.mean()
0.16360632274980608
sns.scatterplot(x=y_test, y=y_predic);

Model Random Forest
model_rF = RandomForestRegressor(n_estimators=40, random_state=100)
model_rF.fit(X_train, y_train)
y_PreD = model_rF.predict(X_test)
print('train score:',model_rF.score(X_train,y_train))
# print("r2_score:",r2_score(y_test,y_PreD))
# print("MSPE",mean_absolute_percentage_error(y_test,y_PreD))
# y_PreD
train score: 0.9816073765726556
# The values for R² range from 0 to 1, which captures 
# the percentage of squared correlation between the predicted and actual values of the target variable.
housing_predictions_RF = model_rF.predict(X_test)
error = mean_squared_error(y_test,housing_predictions_RF)
rmse2 = np.sqrt(error)
rmse2/y_test.mean()
0.1551585253936839
sns.scatterplot(x=y_test, y=y_PreD);

data.to_csv('House_Price_Pred.100623.csv',index=False, encoding='utf-8')
 
